{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfca3043",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "train data: [training.json](../../../data/groundtruth_dataset/Binary_PIP_Classifier/training.json)\n",
    "\n",
    "test data: [testing.json](../../../data/groundtruth_dataset/Binary_PIP_Classifier/testing.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def read_data(filepath):\n",
    "    data = []\n",
    "    with open(filepath,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "#TODO: \n",
    "train_data_path = ''\n",
    "test_data_path = ''\n",
    "\n",
    "train_data = read_data(train_data_path)\n",
    "test_data = read_data(test_data_path)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "eval_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71fa37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set 10544\n",
      "Test Set 2637\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set\", len(train_data))\n",
    "print(\"Test Set\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4cd961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language-wise distribution of train data: \n",
      "    positive  negative  total\n",
      "en      2024      2257   4281\n",
      "zh      3436       301   3737\n",
      "ja       463       471    934\n",
      "it       142       137    279\n",
      "th       141       134    275\n",
      "de       112       128    240\n",
      "es       119       112    231\n",
      "ru        99        95    194\n",
      "ko        96        93    189\n",
      "fr        84       100    184\n",
      "\n",
      "category-wise distribution of train data: \n",
      "              Key  Value\n",
      "0            porn   3002\n",
      "1            drug    772\n",
      "2        Gambling    641\n",
      "3   money-laundry    599\n",
      "4    data_leakage    591\n",
      "5    Crowdturfing    342\n",
      "6      harassment    271\n",
      "7          weapon    162\n",
      "8   fake_document    140\n",
      "9       surrogacy    104\n",
      "10         Others     92\n"
     ]
    }
   ],
   "source": [
    "#language-wise and category-wise distribution of groundtruth dataset\n",
    "def distribution(data_list):\n",
    "    balanced_language = {}\n",
    "    for each in data_list:\n",
    "        lang = each['language']\n",
    "        if lang not in balanced_language:\n",
    "            balanced_language[lang] = {}\n",
    "            balanced_language[lang]['positive'] = 0\n",
    "            balanced_language[lang]['negative'] = 0\n",
    "            balanced_language[lang]['total'] = 0\n",
    "        if int(each['labels']):\n",
    "            balanced_language[lang]['positive'] += 1\n",
    "        else:\n",
    "            balanced_language[lang]['negative'] += 1\n",
    "        balanced_language[lang]['total'] += 1\n",
    "    balanced_language = dict(sorted(balanced_language.items(), key=lambda x: x[1]['total'], reverse=True))\n",
    "    balanced_language = pd.DataFrame(balanced_language).T\n",
    "    print('language-wise distribution of train data: ')\n",
    "    print(balanced_language)\n",
    "    \n",
    "    balanced_category = {}\n",
    "    for each in data_list:\n",
    "        if int(each['labels']):\n",
    "            if each['subcategory'] not in balanced_category:\n",
    "                balanced_category[each['subcategory']] = 0\n",
    "            balanced_category[each['subcategory']] += 1\n",
    "    balanced_category = dict(sorted(balanced_category.items(), key=lambda x: x[1], reverse=True))\n",
    "    balanced_category = pd.DataFrame(balanced_category.items(), columns=['Key', 'Value'])\n",
    "    print('\\ncategory-wise distribution of train data: ')\n",
    "    print(balanced_category)\n",
    "    \n",
    "distribution(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49f0bb",
   "metadata": {},
   "source": [
    "## Binary Text Classifier\n",
    "### Training\n",
    "model name: bert-base-multilingual-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566c7003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created and data ready, starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f487fc2b792b4a9d9e04a4b09f2e8043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f65e2eb9df497a944d592f57256af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95f55b950084839a1f51daffea69cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d994173b9a4b3a82573c506c73102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f55ba1f9984032b977fc3100b73487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3984d531b0fa4b6f95280c0c11087f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce97044a9e84b70b336d6857053f1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b385bed0c3544ddaac72ef4a526bb5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578adf027a1b43109890b9e455a43214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052e6f7f348c4550b25ce4a91d070015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d324ee2df8d44eb18da4e6a1e2d9d547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 8 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b6c7396a2b47d88ecb26e1ef0aea45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 9 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a6e8c41f241709514dc56d449754d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 10 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7bfe4f82e4407c802d339bc6ccb6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 11 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0b4e75bef948e0aacc926d279fc8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 12 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5d55a408d24251a13767feafd81a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 13 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee42ab8a128427eb40108986b0a1947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 14 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068bcfe001f3437f8ef4db1a3fce887a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 15 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d695947218d401196ffc7de3aa3c8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 16 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08db92ed2ab1491589a92f0c71d2d68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 17 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66e3519681b4f428b7f2bf62da76675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 18 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcca705d59184d59bd89d1c5970fab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 19 of 20:   0%|          | 0/1335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(26700, 0.18389842666936723)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "EPOCH_NUM = 14\n",
    "args={'num_train_epochs':EPOCH_NUM, 'output_dir': \"outputs\"}\n",
    "text_model = ClassificationModel(\"bert\", \"bert-base-multilingual-uncased\", args=args)\n",
    "\n",
    "train_df_text = train_df\n",
    "train_df_text['labels'] = train_df_text['labels'].replace(['0','1'],[0,1]) \n",
    "\n",
    "text_model.train_model(train_df_text, output_dir=f\"output_text_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b958617",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6814c5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c63d0b7fcb40a9b65a6eeb2ca11bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfd5a7b074840d79b171595be8bc2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Key        Value\n",
      "0         mcc     0.907409\n",
      "1          tp  1625.000000\n",
      "2          tn   899.000000\n",
      "3          fp    46.000000\n",
      "4          fn    67.000000\n",
      "5       auroc     0.973540\n",
      "6       auprc     0.975187\n",
      "7   eval_loss     0.228150\n",
      "8   precision     0.972472\n",
      "9      recall     0.960402\n",
      "10   F1_score     0.966399\n",
      "\n",
      "language-wise performance of test set:\n",
      "       TP    FP     TN    FN   count  precision    recall  F1_score\n",
      "en  474.0  16.0  568.0  19.0  1077.0   0.967347  0.961460  0.964395\n",
      "zh  854.0  19.0   49.0  18.0   940.0   0.978236  0.979358  0.978797\n",
      "ja  115.0   5.0  111.0  11.0   242.0   0.958333  0.912698  0.934959\n",
      "th   28.0   4.0   31.0  10.0    73.0   0.875000  0.736842  0.800000\n",
      "de   42.0   0.0   28.0   0.0    70.0   1.000000  1.000000  1.000000\n",
      "it   31.0   0.0   31.0   0.0    62.0   1.000000  1.000000  1.000000\n",
      "es   24.0   1.0   26.0   2.0    53.0   0.960000  0.923077  0.941176\n",
      "ru   21.0   0.0   23.0   1.0    45.0   1.000000  0.954545  0.976744\n",
      "ko   16.0   1.0   19.0   6.0    42.0   0.941176  0.727273  0.820513\n",
      "fr   20.0   0.0   13.0   0.0    33.0   1.000000  1.000000  1.000000\n",
      "\n",
      "category-wise performance of test set:\n",
      "                  TP    FN  count    recall\n",
      "porn           720.0  17.0  737.0  0.976934\n",
      "drug           173.0  18.0  191.0  0.905759\n",
      "Gambling       152.0   6.0  158.0  0.962025\n",
      "money-laundry  151.0   3.0  154.0  0.980519\n",
      "data_leakage   152.0   1.0  153.0  0.993464\n",
      "Crowdturfing    87.0   0.0   87.0  1.000000\n",
      "harassment      71.0   1.0   72.0  0.986111\n",
      "fake_document   44.0   8.0   52.0  0.846154\n",
      "weapon          37.0  11.0   48.0  0.770833\n",
      "surrogacy       20.0   2.0   22.0  0.909091\n",
      "Others          18.0   0.0   18.0  1.000000\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "import os, re\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "eval_df_text = eval_df\n",
    "eval_df_text['labels'] = eval_df_text['labels'].replace(['0','1'],[0,1]) \n",
    "model_name = 'outputs/checkpoint-18452-epoch-14'\n",
    "text_model = ClassificationModel(\"bert\", model_name)\n",
    "result_text, model_text_outputs, wrong_predictions = text_model.eval_model(eval_df_text)\n",
    "\n",
    "wrong_texts = [each.text_a for each in wrong_predictions]\n",
    "result_text['precision'] = result_text['tp'] / (result_text['tp'] + result_text['fp'])\n",
    "result_text['recall'] = result_text['tp'] / (result_text['tp'] + result_text['fn'])\n",
    "result_text['F1_score'] = 2 * result_text['precision'] * result_text['recall'] / (result_text['precision'] + result_text['recall'])\n",
    "print(pd.DataFrame(result_text.items(), columns=['Key', 'Value']))\n",
    "\n",
    "language_wise_performance = {}\n",
    "for each in test_data:\n",
    "    lang = each['language']\n",
    "    text = each['text']\n",
    "    if lang not in language_wise_performance:\n",
    "        language_wise_performance[lang] = {}\n",
    "        language_wise_performance[lang]['TP'] = 0\n",
    "        language_wise_performance[lang]['FP'] = 0\n",
    "        language_wise_performance[lang]['TN'] = 0\n",
    "        language_wise_performance[lang]['FN'] = 0\n",
    "    if int(each['labels']) == 1 and text not in wrong_texts:\n",
    "        language_wise_performance[lang]['TP'] += 1\n",
    "    elif int(each['labels']) == 0 and text not in wrong_texts:\n",
    "        language_wise_performance[lang]['TN'] += 1 \n",
    "    elif int(each['labels']) == 0 and text in wrong_texts:\n",
    "        language_wise_performance[lang]['FP'] += 1\n",
    "    elif int(each['labels']) == 1 and text in wrong_texts:\n",
    "        language_wise_performance[lang]['FN'] += 1\n",
    "for lang in language_wise_performance:\n",
    "    language_wise_performance[lang]['count'] = language_wise_performance[lang]['TP'] + language_wise_performance[lang]['FP'] + language_wise_performance[lang]['TN'] + language_wise_performance[lang]['FN']\n",
    "    language_wise_performance[lang]['precision'] = language_wise_performance[lang]['TP'] / (language_wise_performance[lang]['TP'] + language_wise_performance[lang]['FP'])\n",
    "    language_wise_performance[lang]['recall'] = language_wise_performance[lang]['TP'] / (language_wise_performance[lang]['TP'] + language_wise_performance[lang]['FN'])\n",
    "    language_wise_performance[lang]['F1_score'] = 2 * language_wise_performance[lang]['precision'] * language_wise_performance[lang]['recall'] / (language_wise_performance[lang]['precision'] + language_wise_performance[lang]['recall'])\n",
    "language_wise_performance = dict(sorted(language_wise_performance.items(), key=lambda x: x[1]['count'], reverse=True))\n",
    "language_wise_performance = dict(list(language_wise_performance.items())[:10])\n",
    "print('\\nlanguage-wise performance of test set:')\n",
    "print(pd.DataFrame(language_wise_performance).T)\n",
    "\n",
    "category_wise_performance = {}\n",
    "for each in test_data:\n",
    "    if 'subcategory' not in each:\n",
    "        continue\n",
    "    cat = each['subcategory']\n",
    "    text = each['text']\n",
    "    if cat not in category_wise_performance:\n",
    "        category_wise_performance[cat] = {}\n",
    "        category_wise_performance[cat]['TP'] = 0\n",
    "        category_wise_performance[cat]['FN'] = 0\n",
    "    if text in wrong_texts:\n",
    "        category_wise_performance[cat]['FN'] += 1\n",
    "    else:\n",
    "        category_wise_performance[cat]['TP'] += 1\n",
    "for cat in category_wise_performance:\n",
    "    category_wise_performance[cat]['count'] = category_wise_performance[cat]['TP'] + category_wise_performance[cat]['FN']\n",
    "    category_wise_performance[cat]['recall'] = category_wise_performance[cat]['TP'] / category_wise_performance[cat]['count']\n",
    "category_wise_performance = dict(sorted(category_wise_performance.items(), key=lambda x: x[1]['count'], reverse=True))\n",
    "print('\\ncategory-wise performance of test set:')\n",
    "print(pd.DataFrame(category_wise_performance).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e177ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
